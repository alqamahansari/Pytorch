{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1fhMOT2P1ggYEF0KEn6DX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alqamahansari/Pytorch/blob/main/day2_autograd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_BeRe68ZPxN"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Scalar example: verify derivative"
      ],
      "metadata": {
        "id": "vnEoBg3Ra4oM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# x is a leaf tensor we care about\n",
        "x = torch.tensor(2.0, requires_grad=True)\n",
        "print(\"x:\", x, \"requires_grad:\", x.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLF60bz1amXu",
        "outputId": "b5b8a3d3-f2ae-4732-ac3b-6c946e8290a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tensor(2., requires_grad=True) requires_grad: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple function: y = x^2 + 3x + 1\n",
        "y = x**2 + 3*x + 1\n",
        "print(\"y:\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XgDLP8kLavT9",
        "outputId": "c42f0e87-7354-4192-c3d1-ed4a0dda36a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y: tensor(11., grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Backprop: dy/dx goes into x.grad\n",
        "y.backward()\n",
        "print(\"x.grad:\", x.grad)  # should be 2*x + 3 = 7.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwKFNJ_1ayYr",
        "outputId": "522e494b-1739-4abd-d7e8-5f8c7024d5db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.grad: tensor(7.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Vector â†’ scalar: gradient for each element"
      ],
      "metadata": {
        "id": "DGgqGtrhbA1p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.linspace(-2, 2, steps=5, requires_grad=True)\n",
        "print(\"x:\", x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8YpCzfxa1CW",
        "outputId": "e40312fa-f919-47cb-dbb3-41858fc4490a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tensor([-2., -1.,  0.,  1.,  2.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: y = sum(x^2)\n",
        "y = (x**2).sum()\n",
        "print(\"y (scalar):\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvEdOP-obFZZ",
        "outputId": "28c27d68-bc94-4641-8053-2d5663ebc118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y (scalar): tensor(10., grad_fn=<SumBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y.backward()\n",
        "print(\"x.grad:\", x.grad)  # Should be 2*x for each element"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXcT_SjnbHk2",
        "outputId": "6575ffd3-c0a3-499d-bce1-eab01da5ae83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.grad: tensor([-4., -2.,  0.,  2.,  4.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.grad.zero_()\n",
        "\n",
        "z = (3*x + 1).sum()\n",
        "z.backward()\n",
        "print(\"x.grad:\", x.grad)  # Should be 3 for all elements"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToRxfwyWbKDF",
        "outputId": "4c354af3-9a88-4b8a-8913-95b0d3c7b8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.grad: tensor([3., 3., 3., 3., 3.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Non-scalar output: use gradient argument"
      ],
      "metadata": {
        "id": "3T34ziE5bQTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(4.0, requires_grad=True)  # [0,1,2,3]\n",
        "y = x**2\n",
        "print(\"x:\", x)\n",
        "print(\"y:\", y)  # non-scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2o8cO73bNEH",
        "outputId": "d17251fb-4776-481d-a033-83b240aaf226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: tensor([0., 1., 2., 3.], requires_grad=True)\n",
            "y: tensor([0., 1., 4., 9.], grad_fn=<PowBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide gradient (same shape as y)\n",
        "grad_output = torch.ones_like(y)\n",
        "y.backward(grad_output)"
      ],
      "metadata": {
        "id": "tW4RicafbUeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"x.grad:\", x.grad)  # Again 2*x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHEe-MJGbW9I",
        "outputId": "9273f497-9836-4121-ac47-2d8d5a1eff52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.grad: tensor([0., 2., 4., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Stop tracking and detach"
      ],
      "metadata": {
        "id": "y-oVCWRUbZXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(3, requires_grad=True)\n",
        "b = 2 * a\n",
        "c = b.mean()"
      ],
      "metadata": {
        "id": "XcEB3ypHbdQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"a.requires_grad:\", a.requires_grad)\n",
        "print(\"b.requires_grad:\", b.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5TLpzXcbgGF",
        "outputId": "b4a85944-b254-4953-f9c5-aca85cacf4fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.requires_grad: True\n",
            "b.requires_grad: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c.backward()\n",
        "print(\"a.grad:\", a.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgKK7-IjbjbO",
        "outputId": "ca65ad02-ad38-48b4-c22e-876f762175da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a.grad: tensor([0.6667, 0.6667, 0.6667])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now detach b so it no longer tracks gradients\n",
        "a.grad.zero_()\n",
        "b_detached = b.detach()\n",
        "d = b_detached.mean()\n",
        "print(\"b_detached.requires_grad:\", b_detached.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NouyFiaublxC",
        "outputId": "d6caf668-1f69-4d01-e0d8-dca37a9a143b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b_detached.requires_grad: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Gradients accumulate and need zeroing"
      ],
      "metadata": {
        "id": "m0VJAwJkdbbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.tensor(2.0, requires_grad=True)\n",
        "\n",
        "for step in range(3):\n",
        "    y = (w - 1)**2\n",
        "    y.backward()\n",
        "    print(f\"step {step}, w.grad:\", w.grad)\n",
        "\n",
        "    # Zero grad to avoid accumulation\n",
        "    w.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKoaOLeLboKU",
        "outputId": "e190fabb-e246-4984-f16e-85f1f54a18a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0, w.grad: tensor(2.)\n",
            "step 1, w.grad: tensor(2.)\n",
            "step 2, w.grad: tensor(2.)\n"
          ]
        }
      ]
    }
  ]
}